<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Overview | Mitch Joseph</title>
    <link>/courses/example/</link>
      <atom:link href="/courses/example/index.xml" rel="self" type="application/rss+xml" />
    <description>Overview</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Coded with  and  Blogdown
Â© Mitch Joseph, 2020</copyright><lastBuildDate>Sun, 09 Sep 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Overview</title>
      <link>/courses/example/</link>
    </image>
    
    <item>
      <title>Chapters 1-3</title>
      <link>/courses/example/chapter-01-03-notes/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/courses/example/chapter-01-03-notes/</guid>
      <description>&lt;h1 id=&#34;grid-approximation&#34;&gt;Grid Approximation&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Step 1: Define the grid, what are all the values you&#39;re going to consider
p_grid &amp;lt;- seq(from=0, to=1, length.out = 1000)

# Step 2: Define the prior: Assume uniform and assign 1 to every value of p we&#39;re considering. We assign 1 so that the integral sums to 1
prob_p &amp;lt;- rep(1, 1000)

# Step 3: Get the probability of the data, aka, the likelihood. 6 waters, 9 tosses
prob_data &amp;lt;- dbinom(6, size=9, prob=p_grid)

# Step 4: Computer the posterior
posterior &amp;lt;- prob_data * prob_p

# Step 5: Standardize the posterior
posterior &amp;lt;- posterior / sum(posterior)

plot(p_grid, posterior, type = &amp;quot;b&amp;quot;,
     xlab = &amp;quot;probability of water&amp;quot;,
     ylab = &amp;quot;posterior probability&amp;quot;)
mtext(&amp;quot;1000 points&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-01-03_files//figure-html/unnamed-chunk-1-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h1 id=&#34;quadratic-approximation&#34;&gt;Quadratic Approximation&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Step 1: Find the posterior mode.
# Step 2: Once you find the peak of the posterior, estimate the curvature near the peak
# note map() stands for maximum a posteriori aka, the mode of the posterior

library(rethinking)
globe.qa &amp;lt;- map(
  alist(
    w ~ dbinom(9,p), # binomial likelihood
    p ~ dunif(0,1) # uniform prior
  ),
  data = list(w=6))

# display summary of quadratic approximation
# Interpretation: assuming the posterior is Gaussian, it is maximized at 0.67, and its
# standard deviation is 0.16
precis(globe.qa)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        mean        sd      5.5%     94.5%
## p 0.6666665 0.1571338 0.4155363 0.9177967
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;sampling&#34;&gt;Sampling&lt;/h1&gt;
&lt;p&gt;In order to pull samples we need a posterior to pull from. We&amp;rsquo;ll reuse the grid approximation from the globe tossing example.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid &amp;lt;- seq(0, 1, length.out = 1000)
prior &amp;lt;- rep(1, 1000)
likelihood &amp;lt;- dbinom(6, size = 9, prob = p_grid)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now assume we want to draw 10,000 samples from this posterior&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;samples &amp;lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
plot(samples)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-01-03_files//figure-html/unnamed-chunk-4-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;As we can see below, the estimated density of our samples is very similar to our posterior. As we draw more samples it will get more and more similar&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dens(samples)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-01-03_files//figure-html/unnamed-chunk-5-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(posterior)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-01-03_files//figure-html/unnamed-chunk-5-2.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;intervals-of-defined-boundary&#34;&gt;Intervals of defined boundary&lt;/h2&gt;
&lt;p&gt;Suppose we want the probability that the proportion of water is less than 0.5.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sum(posterior[p_grid &amp;lt; 0.5])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1718746
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can perform this same calculation using the samples from the posterior too.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sum(samples &amp;lt; 0.5)/1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1713
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;intervals-of-defined-mass&#34;&gt;Intervals of defined mass&lt;/h2&gt;
&lt;p&gt;These are usually known as confidence intervals. These intervals report two parameter values that contain between them a specified amount of posterior probability, a probability mass.&lt;/p&gt;
&lt;p&gt;If we wanted the lower 80% we could run the code below and see that posterior probability exists below a parameter value of about 0.76.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;quantile(samples, 0.8)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       80% 
## 0.7607608
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly if we wanted the middle 80% interval&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;quantile(samples, c(0.1, 0.9))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       10%       90% 
## 0.4474474 0.8148148
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However we must be careful. These intervals, which we&amp;rsquo;ll call &lt;strong&gt;percentile intervals (PI)&lt;/strong&gt;, assign an equal probability mass to each tail. They do a good job of communitcating the shape of a distribution, as long as the distribution isn&amp;rsquo;t too asymetrical. The &lt;strong&gt;highest posterior density interval (HPDI)&lt;/strong&gt; is the narrowest interval containing the specified probability mass.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s consider an example to illustrate the difference. If we toss a globe three times and it lands on water every time, we&amp;rsquo;ll see that PI excludes the most probable parameter values, near $p = 1$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid &amp;lt;- seq(0, 1, length.out = 1000)
prior &amp;lt;- rep(1, 1000)
likelihood &amp;lt;- dbinom(3, size = 3, prob = p_grid)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
samples &amp;lt;- sample(p_grid, size = 1e4, replace = TRUE, prob = posterior)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;![](/img/statistical-rethinking/notes/Chapter-01-03_files//figure-html/PI vs HPDI-1.png)&lt;!-- --&gt;
Visually we can see that HPDI is narrower, but we can also calculate this below to see that HPDI has a width of about 0.16 in comparison to 0.22 for the percentile interval.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PI_interval &amp;lt;- PI(samples, prob = 0.5)
HPDI_interval &amp;lt;- HPDI(samples, prob = 0.5)

PI_interval[[2]] - PI_interval[[1]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2252252
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HPDI_interval[[2]] - HPDI_interval[[1]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1541542
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HPDI has some advantages over the PI, but in most cases, these two types of interval are very similar. When the posterior is bell shaped, it hardly matters which type of interval you use.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also important to realize that HPDI does have some disadvantages. HPDI is more computationally intensive than PI and suffers from greater &lt;em&gt;simulation variance&lt;/em&gt; meaning that it is sensitive to how many samples you draw from the posterior.&lt;/p&gt;
&lt;h2 id=&#34;point-estimates&#34;&gt;Point Estimates&lt;/h2&gt;
&lt;p&gt;Given the entire posterior distribution, what value should you report? Let&amp;rsquo;s reuse the previous example, of observing three waters out of three tosses. We&amp;rsquo;l consider three examples.&lt;/p&gt;
&lt;p&gt;First we&amp;rsquo;ll look at the parameter value with the highest posterior probability.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid[which.max(posterior)]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or if we have samples from the posterior, we can still approximate the same point.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# chainmode returns the estimated mode of a density computed from samples
chainmode(samples, adj = 0.01)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9837448
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One way we can go beyond using the entire posterior as the estimate is to choose a &lt;strong&gt;loss function&lt;/strong&gt;. The important thing to understand is that different loss functions imply different point estimates.&lt;/p&gt;
&lt;p&gt;Here we see that using an absolute loss function is equivalent (up to sampling variance) to the median. The quadratic loss $(d - p)^2$ is another common loss function, which leads to the posterior mean i.e. mean(samples) as the point estimate.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;loss &amp;lt;- sapply(p_grid, function(d) sum(posterior*abs(d-p_grid)))
p_grid[which.min(loss)]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8408408
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;median(samples)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8458458
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;dummy-data&#34;&gt;Dummy Data&lt;/h2&gt;
&lt;p&gt;Bayesian models are always generative, meaning that they&amp;rsquo;re capable of simulating predictions. We call such simulated data, dummy data. If we wanted to simulate observations for our globe tossing experiment we can use the rbinom() function in r. Let&amp;rsquo;s say we want to generate 100,000 dummy observations. Notice how this is nearly identical to the analytical approach.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Generated&lt;/th&gt;
&lt;th&gt;Analytical&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0.09076&lt;/td&gt;
&lt;td&gt;0.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.42008&lt;/td&gt;
&lt;td&gt;0.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.48916&lt;/td&gt;
&lt;td&gt;0.49&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;model-checking&#34;&gt;Model Checking&lt;/h2&gt;
&lt;p&gt;Model checking means (1) ensuring the model fitting worked correctly and (2) evaluating the adequacy of a model for some purpose.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 2 problem set</title>
      <link>/courses/example/chapter_02_ps/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/courses/example/chapter_02_ps/</guid>
      <description>&lt;h2 id=&#34;r-markdown&#34;&gt;R Markdown&lt;/h2&gt;
&lt;h2 id=&#34;2m1&#34;&gt;2M1&lt;/h2&gt;
&lt;p&gt;First we&amp;rsquo;ll start off by defining our grid using seq(), and defining a uniform prior, just make sure the amount of times you repeat the prior is equal to the lenght.out.&lt;/p&gt;
&lt;p&gt;Defining the likelihoods used the dbinom or density binomial distribution. We start by inputing how many observations were waters, size is equal to the total number of tosses, and prob is equal to our grid.&lt;/p&gt;
&lt;p&gt;Comupting the posterior is the product of likelihood and prior divided by the sum of all those values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Define the grid
p_grid &amp;lt;- seq(from=0, to=1, length.out = 1000)

# Assume a uniform prior 
prior1 &amp;lt;- rep(1, 1000)

# Get the likelihood given: 3 waters and 3 tosses
#                           3 waters and 4 tosses
#                           5 waters and 7 tosses
likelihood1 &amp;lt;- dbinom(3, size=3, prob=p_grid)
likelihood2 &amp;lt;- dbinom(3, size=4, prob=p_grid)
likelihood3 &amp;lt;- dbinom(5, size=7, prob=p_grid)

# Compute posterior
posterior1 &amp;lt;- likelihood1 * prior1
posterior2 &amp;lt;- likelihood2 * prior1
posterior3 &amp;lt;- likelihood3 * prior1

# Standardize
posterior1 &amp;lt;- posterior1 / sum(posterior1)
posterior2 &amp;lt;- posterior2 / sum(posterior2)
posterior3 &amp;lt;- posterior3 / sum(posterior3)

# Plotting the posteriors
plot(p_grid, posterior1, type = &amp;quot;b&amp;quot;,
     xlab = &amp;quot;probability of water&amp;quot;,
     ylab = &amp;quot;posterior probability&amp;quot;)
lines(p_grid, posterior2, type = &amp;quot;b&amp;quot;, col = &amp;quot;red&amp;quot;)
lines(p_grid, posterior3, type = &amp;quot;b&amp;quot;, col = &amp;quot;blue&amp;quot;)
legend(&amp;quot;topleft&amp;quot;, 
       c(&amp;quot;posterior1&amp;quot;, &amp;quot;posterior2&amp;quot;, &amp;quot;posterior3&amp;quot;),
       fill = c(&amp;quot;black&amp;quot;, &amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;))
mtext(&amp;quot;1000 points&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_02_files/figure-html/unnamed-chunk-1-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;2m2&#34;&gt;2M2&lt;/h2&gt;
&lt;p&gt;This problem is identical to the one above, the only thing that&amp;rsquo;s changed is that we have changed our prior to be 0 when p &amp;lt; 0.5 and 1 otherwise. This can all be done in r using the ifelse() function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_02_files/figure-html/pressure-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;2m3&#34;&gt;2M3&lt;/h2&gt;
&lt;p&gt;Since earth is 70% water then there&amp;rsquo;s only a 30% or 0.3 chance that it will land on &amp;lsquo;land&amp;rsquo;. Mars has a 100% or 1.0 chance of landing on &amp;lsquo;land&amp;rsquo; if tossed.&lt;/p&gt;
&lt;p&gt;Below are two identical ways of solving the problem, the second was included as it might not be as obvious how the code in the first part works for people new to r.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ways &amp;lt;- c(.3, 1)
probability &amp;lt;- ways/sum(ways)
probability[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2307692
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Alternative way
earth_land = 1-.7
mars_land = 1
probability_earth = earth_land/(earth_land + mars_land)
probability_earth
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2307692
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2m4&#34;&gt;2M4&lt;/h2&gt;
&lt;p&gt;For the following set of questions I&amp;rsquo;ll be using [bb], [bw], and [ww] to refer to a card that is black on both, black on one side/ white on the other, and white on both sides respectively.&lt;/p&gt;
&lt;p&gt;If [bb] is picked there&amp;rsquo;s a 100% or 1.0 chance that when it&amp;rsquo;s put on the table a black side is facing up.
If [bw] is picked it&amp;rsquo;s a 50% or 0.5 chance.
If [ww] is picked there&amp;rsquo;s a 0% chance that a black side can be facing up.&lt;/p&gt;
&lt;p&gt;Another way of thinking about it is there are two ways a [bb] card can show a black side up, only one way a [bw] card can, and no ways for a [ww] card.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ways &amp;lt;- c(1, 0.5, 0)
probability &amp;lt;- ways/sum(ways)
probability[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6666667
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# ways &amp;lt;- c(2, 1, 0)
# p &amp;lt;- ways/sum(ways)
# p[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2m5&#34;&gt;2M5&lt;/h2&gt;
&lt;p&gt;Now there is an extra [bb] card. I like thinking about it in terms of percentages, so there are two cards that have a 100% chance of showing a black side face up, everything else is the same from 2M4.&lt;/p&gt;
&lt;p&gt;Alternatively you can think of it as two ways a [bb] card show a black side face up, one way for a [bw] card, no ways for [ww], and again two ways for the second [bb] card. Since we can pick either of the [bb] cards we add their probabilities together to get the final result.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ways &amp;lt;- c(2*1, 0.5, 0)
probability &amp;lt;- ways/sum(ways)
probability[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# ways &amp;lt;- c(2, 1, 0, 2)
# probability &amp;lt;- ways/sum(ways)
# sum(probability[1], probability[4])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2m6&#34;&gt;2M6&lt;/h2&gt;
&lt;p&gt;Now we are informed that for every way we can pull [bb] there are two ways we can pull [bw] and three ways to pull [ww]. In the previous examples we were making the implicit assumption that there were equal chances of drawing each card meaning that our prior was 1 for each card. Now we need to adjust our probability given a new prior.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# You could also use: ways &amp;lt;- c(2, 1, 0)
ways &amp;lt;- c(1, 0.5, 0)
prior &amp;lt;- c(1, 2, 3)
likelihood &amp;lt;- ways * prior 
probability &amp;lt;- likelihood/sum(likelihood)
probability
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5 0.5 0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2m7&#34;&gt;2M7&lt;/h2&gt;
&lt;p&gt;To solve this problem we&amp;rsquo;ll look at all the possible combinations of draws that can lead to a black side showing face up on the first draw followed by a white side showing up on the second. Since a [bb] card has two ways it can show a black side face up, I will introduce a new notation [Bb] and [bB] to represent the two different states of the same card. The same logic will be applied to [ww], [bw] need not change because there&amp;rsquo;s only one way a [bw] card can show either black or white.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- data.frame(c(rep(&amp;quot;Bb&amp;quot;, 3), rep(&amp;quot;bB&amp;quot;, 3), c(&amp;quot;bw&amp;quot;, &amp;quot;bw&amp;quot;)), 
                c(rep(c(&amp;quot;bw&amp;quot;, &amp;quot;Ww&amp;quot;, &amp;quot;wW&amp;quot;), 2), c(&amp;quot;Ww&amp;quot;, &amp;quot;wW&amp;quot;)))
knitr::kable(x, align = &#39;cc&#39;, col.names = c(&amp;quot;First Draw&amp;quot;, &amp;quot;Second Draw&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First Draw    Second Draw&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code&gt; Bb            bw      
 Bb            Ww      
 Bb            wW      
 bB            bw      
 bB            Ww      
 bB            wW      
 bw            Ww      
 bw            wW      
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From this we can see that there are six ways a [bb] card can be picked first that would satisfy our observations, and only two ways for the [bw] card to be picked first. There are still no ways a [ww] could be picked first.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# possibilities [Bb, bw], [Bb, Ww], [Bb, wW], [bw, Ww], [bw, wW]
#               [bB, bw], [bB, Ww], [bB, wW]

ways &amp;lt;- c(6, 2, 0)
probability &amp;lt;- ways/sum(ways)
probability[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.75
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2h1&#34;&gt;2H1&lt;/h2&gt;
&lt;p&gt;The relevant information here is that the probability of a panda giving birth to twins given that it&amp;rsquo;s from species A is 10% and species B is 20%. Also, that both species of panda are equally common so. From this we know the following:&lt;/p&gt;
&lt;p&gt;$$ \begin{array}{l}
Pr(twins | A) = 0.1\\&lt;br&gt;
Pr(twins | B) = 0.2\\&lt;br&gt;
Pr(A) = Pr(B) = 0.5
\end{array}$$&lt;/p&gt;
&lt;p&gt;Using Bayes Theorem we can find the following:&lt;/p&gt;
&lt;p&gt;$$ \small \begin{align}
Pr(A | twins) &amp;amp; = \frac{Pr(twins | A)*Pr(A)}{Pr(twins)} \\&lt;br&gt;
Pr(A | twins) &amp;amp; = \frac{0.1 \times 0.5}{0.1 \times 0.5 + 0.2 \times 0.5} \\&lt;br&gt;
&amp;amp; =\frac{0.05}{.15} \\&lt;br&gt;
&amp;amp; =\frac{1}{3}
\end{align}$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;likelihood &amp;lt;- c(0.1, 0.2)
prior &amp;lt;- c(1,1)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
posterior[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3333333
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From this we can see that
$$Pr(B | twins) = 1 - Pr(A | twins) = \frac{2}{3}$$&lt;/p&gt;
&lt;p&gt;Now we can calculate Pr(twins)&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
Pr(twins) &amp;amp; = Pr(twins | A)Pr(A) + Pr(twins | B)Pr(B) \\&lt;br&gt;
&amp;amp; = 0.1 \times \frac{1}{3} + 0.2 \times \frac{2}{3} \\&lt;br&gt;
&amp;amp; = 0.1667
\end{aligned}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;0.1*posterior[1]+0.2*posterior[2]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1666667
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2h2&#34;&gt;2H2&lt;/h2&gt;
&lt;p&gt;We actually already computed this in our solution above:&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
Pr(A | twins) = \frac{Pr(twins | A)*Pr(A)}{Pr(twins)} \\&lt;br&gt;
Pr(A | twins) = \frac{0.1 \times 0.5}{0.1 \times 0.5+0.2 \times 0.5}=\frac{1}{3}
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;posterior[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3333333
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2h3&#34;&gt;2H3&lt;/h2&gt;
&lt;p&gt;Since we know the probability of each species giving birth to twins, we can assume that the probability of giving birth to a singleton is just the complement of our previous probabilities. Therefore:
$$ \small
\begin{align}
Pr(singleton|A) = 0.9\\&lt;br&gt;
Pr(singleton | B) = 0.8
\end{align}$$&lt;/p&gt;
&lt;p&gt;Since we&amp;rsquo;re assuming that the first birth was from twins, we can reuse our probabilities for A and B.
$$\small
\begin{align}
Pr(A) = \frac{1}{3}\\&lt;br&gt;
Pr(B) = \frac{2}{3}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now we can use Bayes Theorem again to solve the problem:
$$\small
\begin{align}
Pr(A | singleton) &amp;amp;= \frac{Pr(singleton|A)Pr(A)}{Pr(singleton)} \\&lt;br&gt;
&amp;amp;= \frac{0.9*\frac{1}{3}}{0.9*\frac{1}{3} + 0.8*\frac{2}{3}} \\&lt;br&gt;
&amp;amp;= \frac{0.3}{0.3 + 0.8333} \\&lt;br&gt;
&amp;amp;= 0.36
\end{align}$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;likelihood &amp;lt;- c(0.9, 0.8)
prior &amp;lt;- c(1/3, 2/3)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
posterior[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.36
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2h4&#34;&gt;2H4&lt;/h2&gt;
&lt;p&gt;I want to preface this solution, this question gave me some trouble and after going to check my answer I felt like there was a lack of consesus over how it should be done I&amp;rsquo;ll do my best to explain my thought process and hopefully someone will be kind enough to give me some feedback .&lt;/p&gt;
&lt;p&gt;We know that the probability this test correctly identifies a panda from species A is 0.8, we also know that the probability this test correctly identifies a panda from species B is 0.65. I&amp;rsquo;ve included the following type error chart to help visualize the test.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_02_files/figure-html/ch2_type_errors.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;We can interpret this as
$$
\begin{array}{l}
Pr(test\space says \space A| A) = 0.8 \\&lt;br&gt;
Pr(test \space says \space B | B) = 0.65
\end{array}
$$&lt;/p&gt;
&lt;p&gt;Since TP + FN = 1 and FP + TN = 1 we can see that&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
Pr(test\space says \space A| B) = 0.35 \\&lt;br&gt;
Pr(test \space says \space B| A) = 0.2
\end{array}
$$&lt;/p&gt;
&lt;p&gt;I hope the chart above helps illustrate why this is the case. Now back to the question. We are first ignoring the previous information about births and computing the posterior probability that the panda is species A given the test tells us it&amp;rsquo;s species A.&lt;/p&gt;
&lt;p&gt;$$\small
\begin{align}
Pr(A| \text{test says } A) &amp;amp;= \frac{Pr(\text{test says } A | A)*Pr(A)}{Pr(\text{test says } A)} \\&lt;br&gt;
&amp;amp;= \frac{Pr(\text{test says } A | A)*Pr(A)}{Pr(\text{test says } A | A)*Pr(A) + Pr(\text{test says } A | B)*Pr(B))} \\&lt;br&gt;
&amp;amp;= \frac{0.8 \times 0.5}{0.8 \times 0.5 + 0.35 \times 0.5} \\&lt;br&gt;
&amp;amp;= \frac{0.4}{0.575} \\&lt;br&gt;
&amp;amp;= 0.696
\end{align}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;likelihood &amp;lt;- c(0.8, 0.35)
prior &amp;lt;- c(1, 1)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
posterior[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6956522
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we will use the birth data&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
Pr(twins | A) = 0.1\\&lt;br&gt;
Pr(twins | B) = 0.2 \\&lt;br&gt;
Pr(A|twins) = \frac{Pr(twins|A)Pr(A)}{Pr(twins)}\\&lt;br&gt;
=\frac{0.1 \times 0.696}{0.1 \times 0.696 + 0.2 \times (1-0.696)} \\&lt;br&gt;
= 0.533
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;likelihood &amp;lt;- c(0.1, 0.2)
prior &amp;lt;- c(0.696, 0.304)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
posterior[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5337423
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 4</title>
      <link>/courses/example/chapter-04-notes/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>/courses/example/chapter-04-notes/</guid>
      <description>&lt;h2 id=&#34;why-things-are-normal&#34;&gt;Why things are normal&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s simulate an experiment. Let&amp;rsquo;s suppose 1,000 people flip a coin 16 times. What we see is that any process that adds together random values from the same distribution converges to a normal distribution. There are multiple ways to conceptualize why this happens, one, is becuase when we have extreme fluctuations, the more we sample, the more they tend to cancel each other out. A large positive fluctuation will cancel out a large negative one. Also from a combinatorical perspective there are more paths (or possible outcomes) that sum to 0 than say 10, but in general, the most likely sum is the one where all the fluctuations cancel each another out, leading to a sum of 0 relative to the mean.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pos &amp;lt;- replicate(1000, sum(runif(16, -1, 1)))
dens(pos, norm.comp = TRUE, col = &amp;quot;blue&amp;quot;, main = &amp;quot;Results of 1,000 people flipping a coin 16 times&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/coin-tossing-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Normality also occurs when we multiply, however this only works when the products are sufficiently small. For example let&amp;rsquo;s look at 12 loci that interact with one another to increase growth rates in organisms by some percentage. The reason this approaches normality is because the product of small numbers very closely approximated by their sum. Take for example, $1.1 * 1.1 = 1.21$ this is nearly equivalent to $1.1 + 1.1 = 1.2$. The smaller the effect of each locus, the better this sum approximation will be.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prod(1 + runif(12, 0, 0.1))
growth &amp;lt;- replicate(1000, prod(1 + runif(12, 0.0, 0.1)))

# sample where the growth rate has a larger effect
growth.big &amp;lt;- replicate(1000, prod(1 + runif(12, 0.0, 0.5)))

# norm.comp = TRUE overlays the normal distribution
dens(growth, norm.comp = TRUE, col = &amp;quot;blue&amp;quot;, main = &amp;quot;Small growth, between 0.0 and 0.1&amp;quot;)
dens(growth.big, norm.comp = TRUE, col = &amp;quot;blue&amp;quot;, main = &amp;quot;Large growth, between 0.0 and 0.5&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/pic1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/pic2.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Even though large deviates multiplied together don&amp;rsquo;t produce Gaussian distributions, on a log scale they do.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;log.big &amp;lt;- replicate(1000, log(prod(1 + runif(12, 0.0, 0.5))))
dens(log.big, norm.comp = TRUE, col = &amp;quot;blue&amp;quot;, main = &amp;quot;Large growth on log scale&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/large-growth-is-log-normal-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;A quick note on notation: The Gaussian is a continuous distribution whereas the binomial is discrete. Probability distributions with only discrete outcomes, like the binomial, are usually called &lt;em&gt;probability mass&lt;/em&gt; functions and are denoted $Pr()$. Continuous ones, like the Gaussian, are called &lt;em&gt;probability densisty&lt;/em&gt; functions, denoted $p()$.&lt;/p&gt;
&lt;h2 id=&#34;linear-regression&#34;&gt;Linear Regression&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s revisit the globe tossing model.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
w \sim Binomial(N,p) \\&lt;br&gt;
p \sim Uniform(0,1)
\end{array}
$$&lt;/p&gt;
&lt;p&gt;Interpretation: We say the outcome, $w$ is distributed binomially with $N$ trials, each one having chance $p$ of success. And the prior $p$ is distributed uniformly with mean 0 and standard deviation 1. It&amp;rsquo;s important to recognize that the binomial is the distribution of the data and the uniform is the distribution of the prior. This should make sense, in the previous homeworks we were constantly putting equal weight for all the prior values.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s look at the variables of a linear regression model.
$$
\begin{array}{l}
y_{i} \sim Normal(\mu_{i}, \sigma) \\&lt;br&gt;
\mu_{i} = \beta x_{i} \\&lt;br&gt;
\beta \sim Normal(0,10) \\&lt;br&gt;
\sigma \sim Exponential(1) \\&lt;br&gt;
x_{i} \sim Normal(0,1)
\end{array}
$$&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll keep this in mind and expand upon it later as we look through an example of height data of Kalahari foragers collected by Nancy Howell. We&amp;rsquo;re goin go focus on adult heights and we&amp;rsquo;re going to build a model to describe the gaussian distribution of these heights.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;Howell1&amp;quot;)
d &amp;lt;- Howell1

# look at adults over the age of 18
d %&amp;lt;&amp;gt;%
  subset(age &amp;gt; 18)
precis(d)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               mean         sd      5.5%     94.5%       histogram
## height 154.6443688  7.7735641 142.87500 167.00500       âââââââââ
## weight  45.0455429  6.4552197  35.28946  55.79536         âââââââ
## age     41.5397399 15.8093044  21.00000  70.02500 âââââââââââââââ
## male     0.4739884  0.5000461   0.00000   1.00000      ââââââââââ
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dens(d$height, norm.comp = TRUE, col = &amp;quot;blue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/load-Howell1-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Looking at the outcome data, we can see that it resembles a Gaussian distribution, so we can assume that the model&amp;rsquo;s likelihood should be Gaussian too. In this example we&amp;rsquo;re going to statrt by saying an individual&amp;rsquo;s height $h_{i}$ is distributed normally with mean $\mu$ and standard deviation $\sigma$.&lt;/p&gt;
&lt;p&gt;$$h_{i} \sim Normal(\mu, \sigma)$$&lt;/p&gt;
&lt;p&gt;Now $\mu$ and $\sigma$ have not been observed, we need to infer them from what we have measured, which in this case is $h$. But we still need to define them, and these are going to act as our priors.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
\mu \sim Normal(178, 20) \\&lt;br&gt;
\sigma \sim Uniform(0, 50)
\end{array}
$$&lt;/p&gt;
&lt;p&gt;Above we&amp;rsquo;re defining $\mu$ as being normally distributed around 178 centimeters with a standard deviation of 20. We started with 178 as the mean height because that&amp;rsquo;s the height of Richard McElreath. This is a broad assumption, it means that 95% probability is between $178\pm 40$ and while this might not be the best choice for a prior it&amp;rsquo;s good enough for now. For $\sigma$ we&amp;rsquo;re saying that it is uniformly distributed from 0 to 50. We know it needs to be positive so bounding it at 0 makes sense, as for the upper bound, choosing a standard deviation of 50cm implies that 95% of individuals lie within 100cm of the average height.&lt;/p&gt;
&lt;p&gt;Whatever your priors are, it&amp;rsquo;s always a good idea to plot them. This will give you a chance to see what assumptions your priors are building into the model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;curve(dnorm(x, 178, 20), from = 100, to = 250, main = &amp;quot;Mu&amp;quot;)
curve(dunif(x, 0, 50), from = -10, to = 60, main = &amp;quot;Sigma&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/shape-of-priors-1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/shape-of-priors-2.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;prior-predictive-distribution&#34;&gt;Prior predictive distribution&lt;/h2&gt;
&lt;p&gt;Now we can use these priors and simulate before actually seeing the data. This is very powerful, it&amp;rsquo;s allowing us to see what our model believes before we feed it the data. We&amp;rsquo;re going to try and build good priors before seeing the data. Note that this is not p-hacking because we&amp;rsquo;re not using the data to educate the model.&lt;/p&gt;
&lt;p&gt;Now to run this simulation all you need to do is sample values from the variables&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sample_mu &amp;lt;- rnorm(1e4, 178, 20)
sample_sigma &amp;lt;- runif(1e4, 0, 50)
prior_h &amp;lt;- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h, norm.comp = TRUE, col = &amp;quot;red&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/simulate-heights-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Looking at this we can see that the distribution is not quite normal, it&amp;rsquo;s actually a T distribution. There&amp;rsquo;s uncertainty about the standard deviation, which is why we see these fat tails. These might not be the best priors in the world but at least we&amp;rsquo;re in the realm of possibility.&amp;rsquo;&amp;rsquo;&lt;/p&gt;
&lt;p&gt;Below we&amp;rsquo;ll consider the same example but with $\mu$ having a standard deviation of 100. Now we can see that this distribution includes some pretty unrealistic possibilities. Like humans smaller than an unfertilized egg, and a large number of people taller than the tallest recorded man in history. We don&amp;rsquo;t need to have seen the data beforehand to know that we can do better than this distribution.
&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/bad-prior-example-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;grid-approximation-of-the-posterior-distribution&#34;&gt;Grid approximation of the posterior distribution&lt;/h2&gt;
&lt;p&gt;Below we are going to use brute force to map out the posterior distribution. Often times this is an impractical approach as it&amp;rsquo;s computationally expensive. But it is worth knowing what the target actually looks like, before we start accepting approximations of it. The code below is&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Establish the range of mu and sigma
mu.list &amp;lt;- seq( from=140, to=160 , length.out=200 )
sigma.list &amp;lt;- seq( from=4 , to=9 , length.out=200 )

# Take all possible combinations of mu and sigma
post &amp;lt;- expand.grid( mu=mu.list , sigma=sigma.list )

# Compute the log-likelihood at each combination of mu and sigma. 
post$LL &amp;lt;- sapply( 1:nrow(post) , function(i) sum( dnorm(
                d$height ,
                mean=post$mu[i] ,
                sd=post$sigma[i] ,
                log=TRUE ) ) )

# Multiply the prior by the likelihood. since the priors and likelihood are on the log scale we add them together which is equivalent to multiplying. 
post$prod &amp;lt;- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
    dunif( post$sigma , 0 , 50 , TRUE )

# Get back to the probability scale from the log scale. We scale all of the log-products by the maximum log-product
post$prob &amp;lt;- exp( post$prod - max(post$prod) )

# Plotting a simple heat map
post %&amp;gt;%
  ggplot(aes(x = mu, y = sigma)) +
  geom_raster(aes(fill = prob),
              interpolate = T) +
  scale_fill_viridis_c(option = &amp;quot;A&amp;quot;) +
  labs(x = expression(mu),
       y = expression(sigma)) +
  theme(panel.grid = element_blank())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/contour-using-ggplot-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Computers are nice, but combinatorics will get you in the end.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;sampling-from-the-posterior&#34;&gt;Sampling from the posterior&lt;/h2&gt;
&lt;p&gt;To study the posterior distribution even more, we&amp;rsquo;re going to sample parameter values from it. Since there are two parameter values, we will randomly sample row numbers in post, then we pull parameter values from those sampled rows.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sample.rows &amp;lt;- sample(1:nrow(post), size = 1e4, replace = TRUE, prob = post$prob)
sample.mu &amp;lt;- post$mu[sample.rows]
sample.sigma &amp;lt;- post$sigma[sample.rows]
# cex: character expansion, size of the points
# pch: plot character
# col.alpha: transparancy factor
# plot( sample.mu , sample.sigma , cex=0.5 , pch=16, col=col.alpha(rangi2,0.1), main = &amp;quot;Samples from the posterior distribution&amp;quot; )
post[sample.rows, ] %&amp;gt;%
  ggplot(aes(x = sample.mu, y = sample.sigma)) +
  geom_point(size = 0.9, alpha = 1/15) +
  scale_fill_viridis_c() +
  labs(x = expression(mu[samples]),
       y = expression(sigma[samples])) +
  theme(panel.grid = element_blank()) +
  ggtitle(&amp;quot;Samples from the posterior distribution&amp;quot;)

# marginal posterior densities of mu and sigma
dens(sample.mu, main = &amp;quot;mu&amp;quot;)
dens(sample.sigma, main = &amp;quot;sigma&amp;quot;)

knitr::kable(data.frame(&amp;quot;HPDI lower&amp;quot; = c(HPDI(sample.mu)[[1]], HPDI(sample.sigma)[[1]]), &amp;quot;HPDI upper&amp;quot; = c(HPDI(sample.mu)[[2]], HPDI(sample.sigma)[[2]]), row.names = c(&amp;quot;sample mu&amp;quot;, &amp;quot;sample sigma&amp;quot;)))
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;HPDI.lower&lt;/th&gt;
&lt;th&gt;HPDI.upper&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;sample mu&lt;/td&gt;
&lt;td&gt;153.869347&lt;/td&gt;
&lt;td&gt;155.175879&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sample sigma&lt;/td&gt;
&lt;td&gt;7.291457&lt;/td&gt;
&lt;td&gt;8.221106&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-1-1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-1-2.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-1-3.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is very cool. We can compare the HPDI of $\mu$ and $\sigma$ to the contour map before and see that is matches up with the outer rings of our map.&lt;/p&gt;
&lt;p&gt;It is important to realize that the posterior is not always Gaussian in shape. The mean $\mu$ is fine, however the standard deviation $\sigma$ can cause problems. Let&amp;rsquo;s reduce the sample size down to 20 heights to help visualize issue. The following code is identical to everything above with the exception of d3.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;d3 &amp;lt;- sample(d$height, size = 20)

mu.list &amp;lt;- seq( from=150, to=170 , length.out=200 )
sigma.list &amp;lt;- seq( from=4 , to=20 , length.out=200 )
post2 &amp;lt;- expand.grid( mu=mu.list , sigma=sigma.list )
post2$LL &amp;lt;- sapply( 1:nrow(post2) , function(i)
    sum( dnorm( d3 , 
                mean=post2$mu[i] , 
                sd=post2$sigma[i] ,
                log=TRUE ) ) )
post2$prod &amp;lt;- post2$LL + dnorm( post2$mu , 178 , 20 , TRUE ) +
    dunif( post2$sigma , 0 , 50 , TRUE )
post2$prob &amp;lt;- exp( post2$prod - max(post2$prod) )

sample2.rows &amp;lt;- sample( 1:nrow(post2) , size=1e4 , replace=TRUE ,
    prob=post2$prob )
sample2.mu &amp;lt;- post2$mu[ sample2.rows ]
sample2.sigma &amp;lt;- post2$sigma[ sample2.rows ]

# plot( sample2.mu , sample2.sigma , cex=0.5 ,col=col.alpha(rangi2,0.1) ,
#     xlab=&amp;quot;mu&amp;quot; , ylab=&amp;quot;sigma&amp;quot; , pch=16, main = &amp;quot;Samples from the posterior distribution&amp;quot;)

post2[sample2.rows, ] %&amp;gt;%
  ggplot(aes(x = sample2.mu, y = sample2.sigma)) +
  geom_point(size = 0.9, alpha = 1/15) +
  scale_fill_viridis_c() +
  labs(x = expression(mu[samples]),
       y = expression(sigma[samples])) +
  theme(panel.grid = element_blank()) +
  ggtitle(&amp;quot;Samples from the posterior distribution&amp;quot;)

dens(sample2.mu, norm.comp = TRUE, main = &amp;quot;mu&amp;quot;, col = &amp;quot;blue&amp;quot;)
dens(sample2.sigma, norm.comp = TRUE, main = &amp;quot;sigma&amp;quot;, col = &amp;quot;blue&amp;quot;)

# Plotting density using ggplot
# ggplot(mapping = aes(sample2.mu)) +
#   geom_density(aes(y = ..density.., color = &amp;quot;red&amp;quot;)) +
#   stat_function(fun = dnorm, args = list(mean = mean(sample2.mu), sd = sd(sample2.mu)), color = &amp;quot;black&amp;quot;) +
#   ggtitle(&amp;quot;Mu&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-2-1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-2-2.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-2-3.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we can see here, when we look at the scatterplot there&amp;rsquo;s a much longer tail. Additionally, when we overlay the normal distribution over sigma we can see that the posterior for $\sigma$ is not Gaussian, but rather has a long tail of uncertainty towards higher values.&lt;/p&gt;
&lt;p&gt;While the posterior distribution of $\sigma$ is often not Gaussian, the distribution of it&amp;rsquo;s logarithm, $\text{log(} \sigma \text{)}$ can be much closer. Notice in the code below that we now take the exp(log_sigma) to convert it back from a continuous parameter to one that is strictly positive. Also note that since the prior log_sigma is continous we can now use a Gaussian distribution.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_logsigma &amp;lt;- quap(
  alist(
  height ~ dnorm(mu, exp(log_sigma)),
  mu ~ dnorm(178, 20),
  log_sigma ~ dnorm(2, 10)
  ), data = d)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When we extract samples it is log_sigma that has the Gaussian distribution so we need to use exp() to get it back to the natural scale.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;posterior &amp;lt;- extract.samples(m_logsigma)
sigma &amp;lt;- exp(posterior$log_sigma)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When there&amp;rsquo;s a lot of data, this won&amp;rsquo;t make much of a difference. However, to use exp() to constrain a parameter to be positive is a useful tool to have.&lt;/p&gt;
&lt;h2 id=&#34;quadratic-approximation&#34;&gt;Quadratic Approximation&lt;/h2&gt;
&lt;p&gt;Our interest is to make quick inferences about the shape of the posterior. The posteriorâs peak will lie at the &lt;strong&gt;maximum a posteriori&lt;/strong&gt; estimate (MAP). So we want to find values of $\mu$ and $\sigma$ that maximize the posterior probability. We&amp;rsquo;ll begin by reuising the code from earlier, recall.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{ll}
h_{i} \sim \text{Normal}(\mu, \sigma) &amp;amp;&amp;amp; \text{height ~ dnorm(mu, sigma)} \\&lt;br&gt;
\mu \sim \text{Normal}(178, 20) &amp;amp;&amp;amp; \text{mu ~ dnorm(178, 20)} \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 50) &amp;amp;&amp;amp; \text{sigma ~ dunif(0, 50)}
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create our formula list
flist &amp;lt;- alist(
  height ~ dnorm(mu, sigma),
  mu ~ dnorm(178, 20),
  sigma ~ dunif(0, 50)
)

# fit the model to the data frame using quadratic approximation, quap, performs maximum a posteriori fitting
m &amp;lt;- quap(flist, d)
precis(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            mean        sd       5.5%      94.5%
## mu    154.65521 0.4171725 153.988488 155.321932
## sigma   7.76153 0.2950041   7.290057   8.233004
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 5.5% and 94.5% are percentile interval boundaries corresponding to an 89% interval. Why 89? Because it&amp;rsquo;s quite a wide range so it shows a high-probability range of parameter values, 89 is also a prime number. When we compare these values to our grid approximation HPDIs we see that they&amp;rsquo;re nearly identical. This is what we should expect to see when the posterior distribution is approximately Gaussian.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s do a fun little example. Let&amp;rsquo;s change the prior $\mu$ so that the standard deviation is 0.1.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m2 &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu ~ dnorm(178, 0.1),
    sigma ~ dunif(0, 50)
  ),
  data = d)

precis(m2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            mean        sd      5.5%    94.5%
## mu    177.86598 0.1002314 177.70579 178.0262
## sigma  24.48462 0.9356075  22.98934  25.9799
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What we see here is actually really cool. Since we specified such a small standard deviation for $\mu$ our model is confident that it must be in a very tight range around 178. This isn&amp;rsquo;t that surprising, but now take a look at $\sigma$, our model is compensating for the fact that our $\mu$ is essentially fixed by drastically changing it&amp;rsquo;s estimates for $\sigma$.&lt;/p&gt;
&lt;h2 id=&#34;sampling-from-quadratic-approximation&#34;&gt;Sampling from quadratic approximation&lt;/h2&gt;
&lt;p&gt;Above we were using quap to get approximations for the posterior, now we will learn how to get samples from the quadratic approximate posterior distribution. For a normal Gaussian distribution, all that we need to describe it is a mean and standard deviation (or it&amp;rsquo;s square, variance). But each parameter $\mu$ and $\sigma$ add a dimension to the distribution. So we just need to add a list of means and a matrix of variances and covariances to describe a multi-dimensional Gaussian distribution.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Get the variance-covariance matrix
vcov(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                mu       sigma
## mu    0.174032882 0.000243017
## sigma 0.000243017 0.087027393
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# A variance-covariance matrix can be broken into two parts
# (1) a vector of variances for the parameters
diag(vcov(m))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         mu      sigma 
## 0.17403288 0.08702739
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# (2) A correlation matrix - how changes in one parameter lead to correlated changes in the others.
cov2cor(vcov(m))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                mu       sigma
## mu    1.000000000 0.001974663
## sigma 0.001974663 1.000000000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, instead of sampling single values from a simple Gaussian distribution, we sample vectors of values from a multi-dimensional Gaussian distribution. Each value from the resulting data frame below is sampling from the posterior, so the mean and standard deviation of each column will be close to our quap model from before. An important note as well, these samples preserve the covariance between $\mu$ and $\sigma$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;post &amp;lt;- extract.samples(m, 1e4)
head(post)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         mu    sigma
## 1 155.3892 8.332031
## 2 154.6343 7.851845
## 3 154.5988 7.112019
## 4 154.6519 7.474216
## 5 154.2998 7.813096
## 6 154.1031 7.961075
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;precis(post)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             mean        sd       5.5%      94.5%     histogram
## mu    154.658694 0.4183489 153.992842 155.323129       âââââââ
## sigma   7.759745 0.2965240   7.288287   8.234882 âââââââââââââ
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-a-predictor&#34;&gt;Adding a predictor&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s look at how the Kalahari foragers height covaries with weight. Below we can clearly see that there is a relationship that should allow us to predict someone&amp;rsquo;s height based off of weight.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plot(d$height ~ d$weight)
ggplot(d, aes(x = weight, y = height)) +
  geom_point()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-5-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define our variables as before:
$$
\begin{array}{lcr}
h_{i} \sim \text{Normal}(\mu_{i}, \sigma) &amp;amp;&amp;amp; \text{[likelihood]} \\&lt;br&gt;
\mu_{i} = \alpha + \beta x_{i} &amp;amp;&amp;amp; \text{[linear model]} \\&lt;br&gt;
\alpha \sim \text{Normal}(178,100) &amp;amp;&amp;amp; [\alpha \text{ prior}] \\&lt;br&gt;
\beta \sim \text{Normal}(0,10) &amp;amp;&amp;amp; [\beta \text{ prior}] \\&lt;br&gt;
\sigma \sim \text{Uniform}(0,50) &amp;amp;&amp;amp; [\sigma \text{ prior}]
\end{array}
$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;likelihood&lt;/em&gt;: This is nearly identical to our definitions from before, except now we indexed $\mu$ and $h$, so they depend on the mean of each row.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;linear model&lt;/em&gt;: $\mu$ is now a linear combination of $\alpha$ and $\beta$. $\alpha$ tells us what the expected height is when $x_{i} = 0$, also known as the intercept. and $\beta$ is the expected change in height, when $x_{i}$ changes by 1 unit.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;priors&lt;/em&gt;: We&amp;rsquo;ve seen $\alpha$ and $\sigma$ before, it&amp;rsquo;s just that $\alpha$ was previously called $\mu$. We also widened the prior for $\alpha$, having a huge standard deviation will allow it to move wherever it needs to.
By having $\beta$ be Gaussian with mean 0 and standard deviation 10, we end up placing just as much probability below zero as it does above zero, and when $\beta = 0$, weight has no relationship to height. This is a more conservative estimate than a perfectly flat prior, but it&amp;rsquo;s still weak, and in this context silly as well because we can see that there&amp;rsquo;s clearly a positive relation between height and weigh. In this example, choosing our prior as such is harmless because there&amp;rsquo;s so much data, however, in other contexts we may need to nudge our golem in the right direction.&lt;/p&gt;
&lt;h3 id=&#34;fitting-the-model&#34;&gt;Fitting the model&lt;/h3&gt;
&lt;p&gt;$$
\begin{array}{lcr}
h_{i} \sim \text{Normal}(\mu_{i}, \sigma) &amp;amp;&amp;amp; \text{height } \sim \text{dnorm(mu, sigma)} \\&lt;br&gt;
\mu_{i} = \alpha + \beta x_{i} &amp;amp;&amp;amp; \text{mu &amp;lt;- a + b*weight} \\&lt;br&gt;
\alpha \sim \text{Normal}(178,100) &amp;amp;&amp;amp; \text{a } \sim \text{dnorm(156, 100)} \\&lt;br&gt;
\beta \sim \text{Normal}(0,10) &amp;amp;&amp;amp; \text{b } \sim \text{dnorm(0,10)} \\&lt;br&gt;
\sigma \sim \text{Uniform}(0,50) &amp;amp;&amp;amp; \text{sigma } \sim \text{dunif(0,10)}
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load the data again
data(Howell1)
d &amp;lt;- Howell1 %&amp;gt;%
  subset(age &amp;gt;= 18)

m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta*weight,
    alpha ~ dnorm(178, 100),
    beta ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d)

precis(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              mean         sd        5.5%       94.5%
## alpha 113.9130600 1.90487830 110.8686966 116.9574234
## beta    0.9042676 0.04191154   0.8372849   0.9712503
## sigma   5.0708291 0.19105548   4.7654855   5.3761726
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interpreting the table: Starting with beta, we see the mean is 0.90, this means that a person 1kg heavier is expected to be 0.90 cm taller. Additionally 89% of the posterior probability lies between 0.84 and 0.97. This suggests that $\beta$ values close to zero or greatly above one are highly incompatible with the data and this model.
The estimate of alpha indicates that a person of weight 0 should be 114cm tall. This is nonsense, but it is often the case that the value of the intercept is uninterpretable without also studying any $\beta$ parameters.
Finally, sigma informs us of the width of the distribution of heights around the mean. Recall that 95% of the probability in a Gaussian distribution lies between two standard deviations. So we can say that 95% of plausible heights lie within 10cm of the mean height. But there is uncertainty about his as indicated by the 89% percentile interval.&lt;/p&gt;
&lt;p&gt;The numbers in the precis output aren&amp;rsquo;t sufficient to describe the quadratic posterior completely. For that, we also need to look at the variance-covariance matrix. We&amp;rsquo;re interested in correlations among parameters - we already have their variance, it&amp;rsquo;s just StdDev^2 - so let&amp;rsquo;s go straight to the correlation matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# precis(m, corr = TRUE) #corr = TRUE 
knitr::kable(cbind(precis(m), cov2cor(vcov(m))), digits = 2)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;mean&lt;/th&gt;
&lt;th&gt;sd&lt;/th&gt;
&lt;th&gt;5.5%&lt;/th&gt;
&lt;th&gt;94.5%&lt;/th&gt;
&lt;th&gt;alpha&lt;/th&gt;
&lt;th&gt;beta&lt;/th&gt;
&lt;th&gt;sigma&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;alpha&lt;/td&gt;
&lt;td&gt;113.91&lt;/td&gt;
&lt;td&gt;1.90&lt;/td&gt;
&lt;td&gt;110.87&lt;/td&gt;
&lt;td&gt;116.96&lt;/td&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;-0.99&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;beta&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;td&gt;0.04&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;-0.99&lt;/td&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sigma&lt;/td&gt;
&lt;td&gt;5.07&lt;/td&gt;
&lt;td&gt;0.19&lt;/td&gt;
&lt;td&gt;4.77&lt;/td&gt;
&lt;td&gt;5.38&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notice that $\alpha$ and $\beta$ are almost perfectly negatively correlated. This means that these two parameters carry the same information - as you change the slope of the line, the best intercept changes to match it. This is fine for now, but in more complex models, strong correlations like this can make it difficult to fit the model to the data. There are several tricks we can do to avoid this.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Centering&lt;/em&gt;: We can subtract the mean of a variable from each value.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# centering weight
d$weight.c &amp;lt;- d$weight - mean(d$weight)

# confirm average of weight.c is zero
# mean(d$weight.c)

# refit the model using weight.c
m2 &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta*weight.c,
    alpha ~ dnorm(178, 100),
    beta ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d)

knitr::kable(cbind(precis(m2), cov2cor(vcov(m2))), digits = 2)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;mean&lt;/th&gt;
&lt;th&gt;sd&lt;/th&gt;
&lt;th&gt;5.5%&lt;/th&gt;
&lt;th&gt;94.5%&lt;/th&gt;
&lt;th&gt;alpha&lt;/th&gt;
&lt;th&gt;beta&lt;/th&gt;
&lt;th&gt;sigma&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;alpha&lt;/td&gt;
&lt;td&gt;154.60&lt;/td&gt;
&lt;td&gt;0.27&lt;/td&gt;
&lt;td&gt;154.17&lt;/td&gt;
&lt;td&gt;155.03&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;beta&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;td&gt;0.04&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sigma&lt;/td&gt;
&lt;td&gt;5.07&lt;/td&gt;
&lt;td&gt;0.19&lt;/td&gt;
&lt;td&gt;4.77&lt;/td&gt;
&lt;td&gt;5.38&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we can see here, beta and sigma remain unchanged, but now the estimate for alpha is equal to the average height. We also now have a more meaningful interpretation of the intercept $\alpha$: the expected value of the outcome, when the predictor (weight) is at its average value.&lt;/p&gt;
&lt;p&gt;Using the coefficients from the model we can now overlay a line defined by quap over the height and weight data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(d, aes(x = weight, y = height)) +
  geom_point() +
  geom_abline(intercept = coef(m)[&amp;quot;alpha&amp;quot;], 
              slope = coef(m)[&amp;quot;beta&amp;quot;],
              color = &amp;quot;royalblue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-9-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This quap line is just the most plausible line out of an infinite universe of lines the posterior distribution has considered. It&amp;rsquo;s useful for getting an impression of the magnitude of the estimated influence of a variable like weight on an outcome like height. But it does a poor job of communicatin uncertainty. Observer in the plots below how adding more data changes the scatter of the lines. As more data is added, our model becomes more confident about the location of the mean.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/plotting-uncertainty-plots-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s important to remember that even bad models can have tight confidence intervals. It may help to think of regression lines as follows: &lt;em&gt;Conditional on the assumption that height and weight are related by a straight line, then this is the most plausible line, and these are its plausible bounds&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prediction-intervals&#34;&gt;Prediction intervals&lt;/h2&gt;
&lt;p&gt;Now we&amp;rsquo;ll walk through getting 89% prediction intervals for actual heights, not just the average height, $\mu$. This means we&amp;rsquo;re going to need to incorporate $\sigma$ and its uncertainties. Looking back at our statistical model $$h_{i} \sim \text{Normal}(\mu, \sigma)$$
we see that our model expects observed heights to be distributed around $\mu$, not right on top of it, and this spread is determined by $\sigma$.&lt;/p&gt;
&lt;p&gt;How to incorporate $\sigma$? Let&amp;rsquo;s start by simulating heights. For any unique weight value, we&amp;rsquo;re going to sample from a Gaussian distribution the correct mean height $\mu$ for that weight, using the correct value of $\sigma$ sampled from the same posterior distribution. Doing this for every weight value of interest gives you a collection of simulated heights that embody the uncertainty in the posterior as well as the uncertainty in the Gaussian likelihood.
&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/plotting-with-sigma-2.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The wide shaded region in the figure represents the area within which the model expects to find 89% of actual heights in the population, at each weight.&lt;/p&gt;
&lt;h2 id=&#34;polynomial-regression&#34;&gt;Polynomial regression&lt;/h2&gt;
&lt;p&gt;The models so far assumed that a straight line describes the relationship, but there&amp;rsquo;s nothing special about straight lines.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;Howell1&amp;quot;)
d &amp;lt;- Howell1

d %&amp;gt;%
  ggplot(aes(x = weight, y = height)) +
  geom_point()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-10-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This relation is clearly curved. There are many ways to model a curved relation, here we&amp;rsquo;ll talk about &lt;strong&gt;polynomial regression&lt;/strong&gt;. Before we continue it&amp;rsquo;s important to note, &lt;strong&gt;in general, polynomial regression is a bad thing to do&lt;/strong&gt;. It&amp;rsquo;s hard to interpret. Nevertheless, we will work through an example, both because it&amp;rsquo;s very common and it will expose some general issues.&lt;/p&gt;
&lt;p&gt;When we talk about polynomial regression, polynomial refers to the equation for $\mu_{i}$, which can have additional terms with squares, cubes, and even higher powers.
In this example, we&amp;rsquo;ll define $\mu$ as follows:
$$
\mu_{i} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i}^2
$$&lt;/p&gt;
&lt;p&gt;The first thing we need to do to fit the model to the data is to &lt;strong&gt;standardize&lt;/strong&gt; the predictor variable. We do this for two reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Interpretation might be easier. For a standardized variable, a change of one unit is equivalent to a change of one standard deviation.&lt;/li&gt;
&lt;li&gt;More importantly, when predictor variables have very large values, sometimes there are numerical glitches.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;d$weight.s &amp;lt;- (d$weight - mean(d$weight))/sd(d$weight)

# No information has been lost in this procedure
d %&amp;gt;%
  ggplot(aes(x = weight.s, y = height)) +
  geom_point()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-11-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta_1*weight.s + beta_2*weight.s^2,
    alpha ~ dnorm(178, 100),
    beta_1 ~ dnorm(0, 10),
    beta_2 ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d)

precis(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              mean        sd       5.5%      94.5%
## alpha  146.663372 0.3736589 146.066193 147.260551
## beta_1  21.400361 0.2898513  20.937122  21.863599
## beta_2  -8.415054 0.2813198  -8.864658  -7.965451
## sigma    5.749788 0.1743171   5.471196   6.028380
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we&amp;rsquo;ll look at a cubic regression.
$$
\mu_{i} = \alpha + \beta_{1}x_{i} + \beta_{2}x_{i}^2 + \beta_{3}x_{i}^3
$$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/notes/Chapter-04_files/figure-html/unnamed-chunk-13-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;We can see here that the linear model is pretty poor at predicting given low and middle weights. The second order polynomial, or parabola, fits much better on the central part of the data in comparison. The third order polynomial, or cubic, fits the data even better. But a better fit doesn&amp;rsquo;t always constitue a better model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 3 problem set</title>
      <link>/courses/example/chapter_03_ps/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/courses/example/chapter_03_ps/</guid>
      <description>&lt;h2 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;Below are my solutions to the end of chapter exercises in Statistical Rethinking by Richard McElreath.&lt;/p&gt;
&lt;p&gt;These results might not be correct. If you catch any errors or mistakes please leave a comment below.&lt;/p&gt;
&lt;h1 id=&#34;easy&#34;&gt;Easy.&lt;/h1&gt;
&lt;p&gt;These problems use the samples from the posterior distribution for the globe tossing example. This code will give you a specific set of samples, so that you can check your answers exactly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid &amp;lt;- seq(from = 0, to = 1, length.out = 1000)
prior &amp;lt;- rep(1, 1000)
likelihood &amp;lt;- dbinom(6, size = 9, prob = p_grid)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)

set.seed(100)
samples &amp;lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3e1&#34;&gt;3E1&lt;/h2&gt;
&lt;p&gt;How much posterior probability lies below p = 0.2?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# sum(posterior[p_grid &amp;lt; 0.2])
sum(samples &amp;lt; 0.2)/1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5e-04
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interpretation: About 0.05% of the posterior probability is below 0.2&lt;/p&gt;
&lt;h2 id=&#34;3e2&#34;&gt;3E2&lt;/h2&gt;
&lt;p&gt;How much posterior probability lies above p = 0.8?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sum(samples &amp;gt; 0.8)/1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1117
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interpretation: About 11% of the posterior probability is above 0.8&lt;/p&gt;
&lt;h2 id=&#34;3e3&#34;&gt;3E3&lt;/h2&gt;
&lt;p&gt;How much posterior probability lies between p = 0.2 and p = 0.8?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sum(samples &amp;gt; 0.2 &amp;amp; samples &amp;lt; 0.8)/1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8878
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interpretation: About 89% of the posterior probability is between 0.2 and 0.8&lt;/p&gt;
&lt;h2 id=&#34;3e4&#34;&gt;3E4&lt;/h2&gt;
&lt;p&gt;20% of the posterior probability lies below which value of p?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;quantile(samples, 0.2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       20% 
## 0.5195195
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Check
sum(samples &amp;lt; 0.5195195)/ 1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1997
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;20% of the posterior probability lies below p = 0.52&lt;/p&gt;
&lt;h2 id=&#34;3e5&#34;&gt;3E5&lt;/h2&gt;
&lt;p&gt;20% of the posterior probability lies above which value of p?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;quantile(samples, 0.8)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       80% 
## 0.7567568
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Check
sum(samples &amp;gt; 0.7567568)/1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1989
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;20% of the posterior probability lies above p = 0.757&lt;/p&gt;
&lt;h2 id=&#34;3e6&#34;&gt;3E6&lt;/h2&gt;
&lt;p&gt;Which values of p contain the narrowest interval equal to 66% of the posterior probability?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HPDI(samples, prob = 0.66)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     |0.66     0.66| 
## 0.5205205 0.7847848
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Check
sum(samples &amp;gt; 0.52 &amp;amp; samples &amp;lt; 0.78)/1e4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6527
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3e7&#34;&gt;3E7&lt;/h2&gt;
&lt;p&gt;Which values of p contain 66% of the posterior probability, assuming equal posterior probabbility both below and above the interval?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PI(samples, prob = 0.66)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       17%       83% 
## 0.5005005 0.7687688
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3m1&#34;&gt;3M1&lt;/h2&gt;
&lt;p&gt;Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid &amp;lt;- seq(from = 0, to = 1, length.out = 1000)
prior &amp;lt;- rep(1, 1000)
likelihood &amp;lt;- dbinom(8, size = 15, prob = p_grid)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior / sum(posterior)
plot(x = p_grid, y = posterior, type = &#39;l&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-9-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;3m2&#34;&gt;3M2&lt;/h2&gt;
&lt;p&gt;Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;samples &amp;lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)

ans_3M2 &amp;lt;- HPDI(samples, prob = 0.90)
ans_3M2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      |0.9      0.9| 
## 0.3383383 0.7317317
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;90% of the posterior probability is between p=0.33 and p=0.72&lt;/p&gt;
&lt;h2 id=&#34;3m3&#34;&gt;3M3&lt;/h2&gt;
&lt;p&gt;Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;w &amp;lt;- rbinom(1e4, size = 15, prob = samples)
simplehist(w)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-11-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ans_3M3 &amp;lt;- sum(w == 8)/1e4
ans_3M3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1428
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# mean(w1 == 8) yields the same result
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3m4&#34;&gt;3M4&lt;/h2&gt;
&lt;p&gt;Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;w &amp;lt;- rbinom(1e4, size = 9, prob = samples)
simplehist(w)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-12-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ans_3M4 &amp;lt;- mean(w == 6)
ans_3M4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1695
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3m5&#34;&gt;3M5&lt;/h2&gt;
&lt;p&gt;Start over at 3M1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earth&amp;rsquo;s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (unsing both priors) to the true value p = 0.7.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid &amp;lt;- seq(from = 0, to = 1, length.out = 1000)
prior2 &amp;lt;- ifelse(p_grid &amp;lt; 0.5, 0, 1)
likelihood &amp;lt;- dbinom(8, size = 15, prob = p_grid)
posterior2 &amp;lt;- likelihood * prior2
posterior2 &amp;lt;- posterior2 / sum(posterior2)
plot(x = p_grid, y = posterior2, type = &#39;l&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-13-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# 3M2
samples2 &amp;lt;- sample(p_grid, prob = posterior2, size = 1e4, replace = TRUE)
ans_3M52 &amp;lt;- HPDI(samples2, prob = 0.90)

# 3M3
w &amp;lt;- rbinom(1e4, size = 15, prob = samples2)
ans_3M53 &amp;lt;- mean(w == 8)

# 3M4
w &amp;lt;- rbinom(1e4, size = 9, prob = samples2)
ans_3M54 &amp;lt;- mean(w == 6)

d &amp;lt;- data.frame(&amp;quot;Problem&amp;quot; = c(&amp;quot;HPDI lower bound&amp;quot;, &amp;quot;HPDI upper bound&amp;quot;, &amp;quot;3M3&amp;quot;, &amp;quot;3M4&amp;quot;), &amp;quot;Uniform prior&amp;quot; = c(ans_3M2[[1]], ans_3M2[[2]], ans_3M3, ans_3M4), &amp;quot;Updated prior&amp;quot; = c(ans_3M52[[1]], ans_3M52[[2]], ans_3M53, ans_3M54))

knitr::kable(d)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Problem&lt;/th&gt;
&lt;th&gt;Uniform prior&lt;/th&gt;
&lt;th&gt;Updated prior&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;HPDI lower bound&lt;/td&gt;
&lt;td&gt;0.3383383&lt;/td&gt;
&lt;td&gt;0.5005005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HPDI upper bound&lt;/td&gt;
&lt;td&gt;0.7317317&lt;/td&gt;
&lt;td&gt;0.7097097&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3M3&lt;/td&gt;
&lt;td&gt;0.1428000&lt;/td&gt;
&lt;td&gt;0.1592000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3M4&lt;/td&gt;
&lt;td&gt;0.1695000&lt;/td&gt;
&lt;td&gt;0.2357000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;3h1&#34;&gt;3H1&lt;/h2&gt;
&lt;p&gt;The practice problems here all use the data below. These data indicate the gender (male = 1, female = 0) of officially reported first and second born children in 100 two-child families.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(homeworkch3)
boys &amp;lt;- sum(birth1) + sum(birth2)

p_grid &amp;lt;- seq(from = 0 , to = 1, length.out = 1000)
prior &amp;lt;- rep(1, 1000)
likelihood &amp;lt;- dbinom(boys, size = 200, prob = p_grid)
posterior &amp;lt;- likelihood * prior
posterior &amp;lt;- posterior/sum(posterior)
plot(x = p_grid, y = posterior, type = &#39;l&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-14-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p_grid[which.max(posterior)]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5545546
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3h2&#34;&gt;3H2&lt;/h2&gt;
&lt;p&gt;Using the sample function, draw 10,000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior density intervals.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;samples &amp;lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)

HPDI(samples, prob = 0.5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      |0.5      0.5| 
## 0.5255255 0.5725726
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HPDI(samples, prob = 0.89)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     |0.89     0.89| 
## 0.5015015 0.6116116
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HPDI(samples, prob = 0.97)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     |0.97     0.97| 
## 0.4764765 0.6286286
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3h3&#34;&gt;3H3&lt;/h2&gt;
&lt;p&gt;Use rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers, each one a count of boys out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to visualize the simulations, but the dens command is probably the easiest way in this case. Does it look like the model fits the data well? That is, does the distribution of predictions include the actual observation as a central, likely outcome?&lt;/p&gt;
&lt;p&gt;As we see here, the distribution seems to fit the data fairly well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;w &amp;lt;- rbinom(1e4, size = 200, prob = samples)
dens(w)
abline(v = 111)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-16-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;3h4&#34;&gt;3H4&lt;/h2&gt;
&lt;p&gt;Now compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births, birth1. How does the model look in this light?&lt;/p&gt;
&lt;p&gt;As we can see below our model overestimates the number of boys for the first child.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;w &amp;lt;- rbinom(1e4, size = 100, prob = samples)
dens(w)
abline(v = sum(birth1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-17-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;3h5&#34;&gt;3H5&lt;/h2&gt;
&lt;p&gt;The model assumes that sex of first and second births are independent. To check this assumption, focus now on the second births that followed female first borns.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compare 10,000 simulated counts of boys to only those second births that followed girls.&lt;/li&gt;
&lt;li&gt;To do this correctly, you need to count the number of first borns who were girls and simulate that many births, 10,000 times.&lt;/li&gt;
&lt;li&gt;Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Below we can see that the our model severly underfits our data, suggesting that births are probably not independent of one another.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Count the number of first borns who were girls
births &amp;lt;- birth2[birth1 == 0]
girl_first &amp;lt;- length(births)

w &amp;lt;- rbinom(1e4, size = girl_first, prob = samples)
dens(w)
abline(v = sum(births))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_03_files/figure-html/unnamed-chunk-18-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 4 problem set</title>
      <link>/courses/example/chapter_04_ps/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      <guid>/courses/example/chapter_04_ps/</guid>
      <description>&lt;h2 id=&#34;4e1&#34;&gt;4E1&lt;/h2&gt;
&lt;p&gt;In the model definition below, which line is the likelihood?
$$
\begin{array}{l}
y_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu \sim \text{Normal}(0, 10) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 10)
\end{array}
$$&lt;/p&gt;
&lt;p&gt;In this example $y_{i}$ is the likelihood.&lt;/p&gt;
&lt;h2 id=&#34;4e2&#34;&gt;4E2&lt;/h2&gt;
&lt;p&gt;In the model definition just above, how many parameters are in the posterior distribution?&lt;/p&gt;
&lt;p&gt;Parameters are defined as having a distribution, so in this case there are two parameters, $\mu$ and $\sigma$.&lt;/p&gt;
&lt;h2 id=&#34;4e3&#34;&gt;4E3&lt;/h2&gt;
&lt;p&gt;Using the model definition above, write down the appropriate form of Bayes&amp;rsquo; theorem that includes the proper likelihood and prior.&lt;/p&gt;
&lt;p&gt;Refering from page 83, we have
$$
\small
Pr(\mu,\sigma|y) = \frac{\prod_{i}\text{Normal}(y_{i}|\mu,\sigma)\text{Normal}(\mu|0,10)\text{Uniform}(\sigma|0,10)}{\int \int \prod_{i}\text{Normal}(y_{i}|\mu,\sigma)\text{Normal}(\mu|0,10)\text{Uniform}(\sigma|0,10)d\mu d\sigma}
$$&lt;/p&gt;
&lt;h2 id=&#34;4e4&#34;&gt;4E4&lt;/h2&gt;
&lt;p&gt;In the model definition below, which line is the linear model?
$$
\begin{array}{l}
y_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu = \alpha + \beta x_{i} \\&lt;br&gt;
\alpha \sim \text{Normal}(0,10) \\&lt;br&gt;
\beta \sim \text{Normal}(0,1) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0,10)
\end{array}
$$
Here we have $y_{i}$ is the likelihood, $\alpha$, $\beta$, and $\sigma$ are all priors. Leaving $\mu$ as the linear model.&lt;/p&gt;
&lt;h2 id=&#34;4e5&#34;&gt;4E5&lt;/h2&gt;
&lt;p&gt;In the model definition just above, how many parameters are in the posterior distribution?&lt;/p&gt;
&lt;p&gt;We sort of answered that in the question above, it&amp;rsquo;s all the stochastic relationships, or variables defined probabilistically, read the priors. So $\alpha$, $\beta$, and $\sigma$ are all the parameters in the distribution. $\mu$ is not a parameter because it is defined deterministically instead of probabilistically.&lt;/p&gt;
&lt;h2 id=&#34;4m1&#34;&gt;4M1&lt;/h2&gt;
&lt;p&gt;For the model definition below, simulate observed heights from the prior (not the posterior).
$$
\begin{array}{l}
y_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu \sim \text{Normal}(0, 10) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 10)
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sample_mu &amp;lt;- rnorm(1e4, 0, 10)
sample_sigma &amp;lt;- runif(1e4, 0, 10)
prior_y &amp;lt;- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_y)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_04_files/figure-html/unnamed-chunk-1-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;4m2&#34;&gt;4M2&lt;/h2&gt;
&lt;p&gt;Translate the model just above into a map formula&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;flist &amp;lt;- alist(
  y ~ dnorm(mu, sigma),
  mu ~ dnorm(0, 10),
  sigma ~ dunif(0, 10)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4m3&#34;&gt;4M3&lt;/h2&gt;
&lt;p&gt;Translate the map model formula below into a mathematical definition.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;flist &amp;lt;- alist(
  y ~ dnorm(mu, sigma),
  mu &amp;lt;- a + b*x,
  a ~ dnorm(0, 50),
  b ~ dunif(0, 10),
  sigma ~ dunif(0, 50)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;$$
\begin{array}{l}
y_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu = \alpha + \beta x_{i} \\&lt;br&gt;
\alpha \sim \text{Normal}(0, 50) \\&lt;br&gt;
\beta \sim \text{Uniform}(0, 10) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 50)
\end{array}
$$&lt;/p&gt;
&lt;h2 id=&#34;4m4&#34;&gt;4M4&lt;/h2&gt;
&lt;p&gt;A sample of students is measured for height each year for 3 years. After the third year, you want to fit a linear regression predicting heigh using year as a predictor. Write down the mathematical model definition for this regression, using any variable names and priors you choose. Be prepared to defend your choice of priors.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
h_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu = \alpha + \beta x_{i} \\&lt;br&gt;
\alpha \sim \text{Normal}(140, 20) \\&lt;br&gt;
\beta \sim \text{Normal}(4, 2) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 50)
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;a &amp;lt;- rnorm(1e4, 140, 20)
b &amp;lt;- rnorm(1e4, 4, 2)
# x_i &amp;lt;- ceiling(runif(1e4, 0, 3))
x_i &amp;lt;- sample(1:3, 1e4, replace = TRUE)
# plot(x_i)
sample_mu &amp;lt;- a + b*x_i
sample_sigma &amp;lt;- runif(1e4, 0, 20)
prior_y &amp;lt;- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_y)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_04_files/figure-html/unnamed-chunk-4-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;For $\alpha$ I chose a mean of 140 because we don&amp;rsquo;t know the age of the students, and this seems like a pretty safe average, additionally, a standard deviation of 20 implies that 95% of the data will lie within the range $140 \pm 40$. We know that most students aren&amp;rsquo;t shrinking so $\beta$ doesn&amp;rsquo;t have to include negative values, by centering it at 4, with standard deviation of 2, we leave room for students to not grow at all, while still allowing for upwards of 8cm of growth per year which I think is adequate. $\sigma$ was chosen to be uniformly distributed from 0 to 20 to give us a decent amount of wiggle room if needed.&lt;/p&gt;
&lt;h2 id=&#34;4m5&#34;&gt;4M5&lt;/h2&gt;
&lt;p&gt;Now suppose I tell you that the average height in the first year was 120cm and that every student got taller each year. Does this information lead you to change your choice of priors? How?&lt;/p&gt;
&lt;p&gt;Yes, since the average height is 120cm we know we&amp;rsquo;re dealing with younger kids. Given this information we can center $\alpha$ around this new average of 120cm, we&amp;rsquo;ll increase $\beta$ because younger kids should grow more each year. Lastly, we&amp;rsquo;ll decrease sigma because we&amp;rsquo;re less likely to see children at full height.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
h_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu = \alpha + \beta x_{i} \\&lt;br&gt;
\alpha \sim \text{Normal}(120, 10) \\&lt;br&gt;
\beta \sim \text{Normal}(6, 2) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 10)
\end{array}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;a &amp;lt;- rnorm(1e4, 120, 10)
b &amp;lt;- rnorm(1e4, 6, 2)
x_i &amp;lt;- sample(1:3, 1e4, replace = TRUE)
sample_mu &amp;lt;- a + b*x_i
sample_sigma &amp;lt;- runif(1e4, 0, 10)
prior_y &amp;lt;- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_y)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_04_files/figure-html/unnamed-chunk-5-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;4m6&#34;&gt;4M6&lt;/h2&gt;
&lt;p&gt;Now suppose I tell you that the variance among heights for students of the same age is never more than 64cm. How does this lead you to revise your priors?&lt;/p&gt;
&lt;p&gt;If the variance is never more than 64cm, then the standard deviation shoudn&amp;rsquo;t be more than $\sqrt{64} = 8\text{cm}$. We had already lowered our estimates for $\sigma$ but we&amp;rsquo;ll just lower it slightly more.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
h_{i} \sim \text{Normal}(\mu, \sigma) \\&lt;br&gt;
\mu = \alpha + \beta x_{i} \\&lt;br&gt;
\alpha \sim \text{Normal}(120, 10) \\&lt;br&gt;
\beta \sim \text{Normal}(6, 2) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 8)
\end{array}
$$&lt;/p&gt;
&lt;h2 id=&#34;4h1&#34;&gt;4H1&lt;/h2&gt;
&lt;p&gt;the weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals. That is, fill in the table below, using model-based predictions.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Individual&lt;/th&gt;
&lt;th&gt;weight&lt;/th&gt;
&lt;th&gt;expected height&lt;/th&gt;
&lt;th&gt;89% interval&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;46.95&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;43.72&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;64.78&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;32.59&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;54.63&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;Howell1&amp;quot;)
d &amp;lt;- Howell1
d$weight.s &amp;lt;- (d$weight - mean(d$weight))/sd(d$weight)
weight.seq &amp;lt;- c(46.95, 43.72, 64.78, 32.59, 54.63)
weight.seq.s &amp;lt;- (weight.seq - mean(d$weight))/sd(d$weight)

# build model
m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta*weight.s,
    alpha ~ dnorm(178, 100),
    beta ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d) 

# simulate heights
sim.height &amp;lt;- sim(m, data = list(weight.s = weight.seq.s))

# calculate mean height and HPDI intervals
height.mean &amp;lt;- apply(sim.height, 2, mean)
height.HPDI &amp;lt;- apply(sim.height, 2, HPDI)

data.frame(cbind(&amp;quot;expected height&amp;quot; = height.mean, 
                 &amp;quot;HPDI lower&amp;quot; = height.HPDI[1,], 
                 &amp;quot;HPDI upper&amp;quot; = height.HPDI[2,] ))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   expected.height HPDI.lower HPDI.upper
## 1        158.1460   144.1036   173.4390
## 2        152.7490   137.8508   166.2481
## 3        189.4287   174.8164   203.7536
## 4        133.4373   119.0272   148.5409
## 5        171.7682   157.8283   187.3320
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4h2&#34;&gt;4H2&lt;/h2&gt;
&lt;p&gt;Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right you should end up with a new data frame with 192 rows in it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;Howell1&amp;quot;)
d &amp;lt;- Howell1 %&amp;gt;%
  subset(age &amp;lt; 18)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;a&#34;&gt;(a)&lt;/h3&gt;
&lt;p&gt;Fit a linear regression to these data, using map. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets.&lt;/p&gt;
&lt;p&gt;Children under the age of 18 encompass a pretty wide range of heights so I&amp;rsquo;m going to pick an $\alpha$ that incorporates the range from 60cm to 180cm. $\beta$ and $\sigma$ were chosen weakly just to give ourselves enough room to work.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta * weight,
    alpha ~ dnorm(120, 30),
    beta ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d
)

precis(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            mean         sd      5.5%     94.5%
## alpha 58.366630 1.39577162 56.135918 60.597343
## beta   2.714082 0.06823543  2.605028  2.823135
## sigma  8.437320 0.43058708  7.749159  9.125481
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We interpret this as the average height when weight is 0 is 58.37cm. For every 10 units of increase in weight, we&amp;rsquo;d expect a person to be 27.1cm taller.&lt;/p&gt;
&lt;h3 id=&#34;b&#34;&gt;(b)&lt;/h3&gt;
&lt;p&gt;Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the 89% HPDI for the predicted heights.&lt;/p&gt;
&lt;p&gt;I personally prefer the graphics of ggplot, so below I used a slightly different method to that used in the book.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# model from above
m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta * weight,
    alpha ~ dnorm(120, 30),
    beta ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d
)


weight.seq &amp;lt;- seq(from = 0, to = max(d$weight), by = 1)
pred_dat &amp;lt;- list(weight = weight.seq)
mu &amp;lt;- link(m, data = pred_dat)
mu.mean &amp;lt;- apply(mu, 2, mean)
mu.HPDI &amp;lt;- apply(mu, 2, HPDI, prob = 0.89)
sim.height &amp;lt;- sim(m, data = pred_dat)
height.HPDI &amp;lt;- apply(sim.height, 2, HPDI, prob = 0.89)

df &amp;lt;- data.frame(cbind(weight.seq, 
                        mu.mean, 
                        &amp;quot;mu.lower&amp;quot; = t(mu.HPDI)[,1],
                        &amp;quot;mu.upper&amp;quot; = t(mu.HPDI)[,2],
                        &amp;quot;HPDI.lower&amp;quot; = t(height.HPDI)[,1],
                        &amp;quot;HPDI.upper&amp;quot; = t(height.HPDI)[,2]))

ggplot() +
  geom_ribbon(data = df,
              aes(x = weight.seq, y = mu.mean,
                  ymin = HPDI.lower, ymax = HPDI.upper),
              fill = &amp;quot;grey83&amp;quot;) +  
  geom_smooth(data = df, 
              aes(x = weight.seq, y = mu.mean,
                  ymin = mu.lower, ymax = mu.upper),
              stat = &amp;quot;identity&amp;quot;,
              fill = &amp;quot;grey70&amp;quot;,
              alpha = 1,
              size = 1/2) +
  geom_point(data = d, 
              aes(x = weight, y = height)) +
  coord_cartesian(xlim = range(d$weight),
                    ylim = range(d$height)) +
  labs(x = &amp;quot;Weight&amp;quot;,
         y = &amp;quot;Height&amp;quot;) +
  theme(panel.grid = element_blank())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_04_files/figure-html/unnamed-chunk-9-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h3 id=&#34;c&#34;&gt;(c)&lt;/h3&gt;
&lt;p&gt;What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don&amp;rsquo;t have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.&lt;/p&gt;
&lt;p&gt;The data is curved and a straight line really doesn&amp;rsquo;t fit the data very well. It&amp;rsquo;s ok for some of the middle weights but does a very poor job at either extreme. Given what we&amp;rsquo;ve learned so far, I think a second order polynomial function would be best.&lt;/p&gt;
&lt;h2 id=&#34;4h3&#34;&gt;4H3&lt;/h2&gt;
&lt;p&gt;Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, &amp;ldquo;That&amp;rsquo;s silly. Everyone knows that it&amp;rsquo;s only the &lt;em&gt;logarithm&lt;/em&gt; of body weight that scales with height!&amp;rdquo; Let&amp;rsquo;s take your colleague&amp;rsquo;s advice and see what happens.&lt;/p&gt;
&lt;h3 id=&#34;a-1&#34;&gt;(a)&lt;/h3&gt;
&lt;p&gt;Model the relationship between height (cm) and the natural logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic approximation.&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{l}
h_{i} \sim \text{Normal}(\mu_{i}, \sigma) \\&lt;br&gt;
\mu_{i} = \alpha + \beta\text{log}(w_{i}) \\&lt;br&gt;
\alpha \sim \text{Normal}(178, 100) \\&lt;br&gt;
\beta \sim \text{Normal}(0, 100) \\&lt;br&gt;
\sigma \sim \text{Uniform}(0, 50)
\end{array}
$$
where $h_{i}$ is the height of individual $i$ and $w_{i}$ is the weight (in kg) of individual $i$. The function for computing a natural log in R is just log. Can you interpret the resulting estimates?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;Howell1&amp;quot;)
d &amp;lt;- Howell1
d$weight.s &amp;lt;- (d$weight - mean(d$weight))/sd(d$weight)
d$weight.s2 &amp;lt;- d$weight.s^2

m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta*log(weight),
    alpha ~ dnorm(178, 100),
    beta ~ dnorm(0, 100),
    sigma ~ dunif(0, 50)
  ), data = d
)

precis(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             mean        sd       5.5%      94.5%
## alpha -23.784150 1.3351132 -25.917919 -21.650381
## beta   47.075315 0.3825445  46.463935  47.686695
## sigma   5.134688 0.1556673   4.885902   5.383475
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a little funky to interpret to interpret.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\alpha$: means that when log weight is equal to zero, height is equal to -23.78.&lt;/li&gt;
&lt;li&gt;$\beta$: means that a one unit increase in log weight corresponds to a 47.08cm increase in height.&lt;/li&gt;
&lt;li&gt;$\sigma$: means that the standard deviation in height predictions is 5.13cm.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;b-1&#34;&gt;(b)&lt;/h3&gt;
&lt;p&gt;Begin with this plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(height ~ weight, data=Howell1,
     col=col.alpha(rangi2, 0.4))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_04_files/figure-html/unnamed-chunk-11-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Then use samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the predicted mean height as a function of weight&lt;/li&gt;
&lt;li&gt;the 97% HPDI for the mean&lt;/li&gt;
&lt;li&gt;the 97% HPDI for predicted heights&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Like I mentioned before, I prefer ggplot, so things might look a little different on my end. But the code is essentially identical to part b in 4H2. The only thing we need to change is the probability ranges for our HPDI, and of course use the new model we defined in part a.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m &amp;lt;- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu &amp;lt;- alpha + beta*log(weight),
    alpha ~ dnorm(178, 100),
    beta ~ dnorm(0, 100),
    sigma ~ dunif(0, 50)
  ), data = d
)

weight.seq &amp;lt;- seq(from = 0, to = max(d$weight), by = 1)
pred_dat &amp;lt;- list(weight = weight.seq)
mu &amp;lt;- link(m, data = pred_dat)
mu.mean &amp;lt;- apply(mu, 2, mean)
mu.HPDI &amp;lt;- apply(mu, 2, HPDI, prob = 0.97)
sim.height &amp;lt;- sim(m, data = pred_dat)
height.HPDI &amp;lt;- apply(sim.height, 2, HPDI, prob = 0.97)

df &amp;lt;- data.frame(cbind(weight.seq, 
                        mu.mean, 
                        &amp;quot;mu.lower&amp;quot; = t(mu.HPDI)[,1],
                        &amp;quot;mu.upper&amp;quot; = t(mu.HPDI)[,2],
                        &amp;quot;HPDI.lower&amp;quot; = t(height.HPDI)[,1],
                        &amp;quot;HPDI.upper&amp;quot; = t(height.HPDI)[,2]))

ggplot() +
  geom_ribbon(data = df,
              aes(x = weight.seq, y = mu.mean,
                  ymin = HPDI.lower, ymax = HPDI.upper),
              fill = &amp;quot;grey83&amp;quot;) +  
  geom_smooth(data = df, 
              aes(x = weight.seq, y = mu.mean,
                  ymin = mu.lower, ymax = mu.upper),
              stat = &amp;quot;identity&amp;quot;,
              fill = &amp;quot;grey70&amp;quot;,
              alpha = 1,
              size = 1/2) +
  geom_point(data = d, 
              aes(x = weight, y = height)) +
  coord_cartesian(xlim = range(d$weight),
                    ylim = range(d$height)) +
  labs(x = &amp;quot;Weight&amp;quot;,
         y = &amp;quot;Height&amp;quot;) +
  theme(panel.grid = element_blank())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/statistical-rethinking/ps/Chapter_04_files/figure-html/unnamed-chunk-12-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
